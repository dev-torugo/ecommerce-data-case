{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "860ab1b0-45d1-4e19-8517-48a12241b6cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "#Criar sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('RNP - E-Commerce Case - Victor Hugo') \\\n",
    "    .config('spark.sql.legacy.pathOptionBehavior.enabled', True) \\\n",
    "    .config('spark.databricks.delta.formatCheck.enabled', False)  \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Configurar as opções de conexão ao banco de dados\n",
    "credenciais = yaml.load(open('./credenciais.yml'))\n",
    "propriedades = {\n",
    "    \"user\": credenciais['database']['username'],\n",
    "    \"password\": credenciais['database']['password'],\n",
    "    \"driver\": credenciais['database']['driver'],\n",
    "    \"url\": credenciais['database']['url']\n",
    "}\n",
    "\n",
    "jdbc_url = propriedades[\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bdfs = dbutils.fs.mkdirs(\"/Users/dev-torugo\")\n",
    "if create_bdfs:\n",
    "    print(\"DBFS Criado\")\n",
    "else:\n",
    "    print(\"Criação DBFS falhou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99e06b9f-ac13-4579-88f0-4636e6aeef21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "The spark context has stopped and the driver is restarting. Your notebook will be automatically reattached.",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QUESTÃO 3 - No Notebook crie lógica para salvar cada tabela como parquet\n",
    "\n",
    "# Configurações de conexão com o banco de dados\n",
    "database_url = propriedades['url']\n",
    "\n",
    "pgsql_dfs = {}\n",
    "\n",
    "# Obtendo a lista de todas as tabelas do banco de dados\n",
    "query = \"(SELECT table_name FROM information_schema.tables WHERE table_schema = 'public') AS tables\"\n",
    "tabelas_ecommerce = spark.read.jdbc(url=database_url, table=query, properties=propriedades)\n",
    "\n",
    "# Excluindo as tabelas que você deseja evitar\n",
    "tabelas_excluir = [\"pg_stat_statements\", \"pg_buffercache\"]\n",
    "tabelas_filtradas = tabelas_ecommerce.filter(~tabelas_ecommerce.table_name.isin(tabelas_excluir))\n",
    "\n",
    "# Coletando a lista final de tabelas a serem salvas como Parquet\n",
    "tabelas = tabelas_filtradas.select(\"table_name\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Loop através das tabelas e salvando como Parquet\n",
    "for tabela in tabelas:\n",
    "    query = f\"(SELECT * FROM {tabela}) AS subquery\"\n",
    "    tabela_pgsql = spark.read.jdbc(url=database_url, table=query, properties=propriedades)\n",
    "    nome_parquet = f\"/Users/dev-torugo/{tabela}.parquet\"\n",
    "    tabela_pgsql.write.parquet(nome_parquet, mode=\"overwrite\")\n",
    "    pgsql_dfs[tabela] = tabela_pgsql\n",
    "    print(f\"{nome_parquet} salvo\")\n",
    "display(dbutils.fs.ls(\"/Users/dev-torugo/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTÃO 4 - No notebook crie um merge entre a tabela JDBC e os arquivos parquet, o merge deve conter a lógica de insert, update e delete.\n",
    "\n",
    "#QUERYS QUE SERÃO UTILIZADAS NA ROTINA DE MERGE\n",
    "merge_querys = {\n",
    "    \"customers\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.customer_number = source.customer_number\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.customer_number = source.customer_number,\n",
    "                            target.customer_name = source.customer_name,\n",
    "                            target.contact_last_name = source.contact_last_name,\n",
    "                            target.contact_first_name = source.contact_first_name,\n",
    "                            target.phone = source.phone,\n",
    "                            target.address_line1 = source.address_line1,\n",
    "                            target.address_line2 = source.address_line2,\n",
    "                            target.city = source.city,\n",
    "                            target.state = source.state,\n",
    "                            target.postal_code = source.postal_code,\n",
    "                            target.country = source.country,\n",
    "                            target.sales_rep_employee_number = source.sales_rep_employee_number,\n",
    "                            target.credit_limit = source.credit_limit\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "\n",
    "    \"employees\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.employee_number = source.employee_number\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.employee_number = source.employee_number,\n",
    "                            target.last_name = source.last_name,\n",
    "                            target.first_name = source.first_name,\n",
    "                            target.extension = source.extension,\n",
    "                            target.email = source.email,\n",
    "                            target.office_code = source.office_code,\n",
    "                            target.reports_to = source.reports_to,\n",
    "                            target.job_Title = source.job_Title\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "\n",
    "    \"offices\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.office_code = source.office_code\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.office_code = source.office_code,\n",
    "                            target.city = source.city,\n",
    "                            target.phone = source.phone,\n",
    "                            target.address_line1 = source.address_line1,\n",
    "                            target.address_line2 = source.address_line2,\n",
    "                            target.state = source.state,\n",
    "                            target.country = source.country,\n",
    "                            target.postal_code = source.postal_code,\n",
    "                            target.territory = source.territory\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "\n",
    "\n",
    "    \"orderdetails\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.order_number = source.order_number AND target.product_code = source.product_code\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.order_number = source.order_number,\n",
    "                            target.product_code = source.product_code,\n",
    "                            target.quantity_ordered = source.quantity_ordered,\n",
    "                            target.price_each = source.price_each,\n",
    "                            target.order_line_number = source.order_line_number\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "\n",
    "    \"orders\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.order_number = source.order_number\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.order_number = source.order_number,\n",
    "                            target.order_date = source.order_date,\n",
    "                            target.required_date = source.required_date,\n",
    "                            target.shipped_date = source.shipped_date,\n",
    "                            target.status = source.status,\n",
    "                            target.comments = source.comments,\n",
    "                            target.customer_number = source.customer_number\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "\n",
    "\n",
    "    \"payments\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.check_number = source.check_number\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.customer_number = source.customer_number,\n",
    "                            target.check_number = source.check_number,\n",
    "                            target.payment_date = source.payment_date,\n",
    "                            target.amount = source.amount\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "\n",
    "    \"product_lines\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.product_line = source.product_line\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.product_line = source.product_line,\n",
    "                            target.text_description = source.text_description,\n",
    "                            target.html_description = source.html_description,\n",
    "                            target.image = source.image\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\",\n",
    "    \"products\": f\"\"\"\n",
    "                    MERGE INTO tabela_delta AS target\n",
    "                    USING tabela_postgresql AS source\n",
    "                    ON target.product_code = source.product_code\n",
    "                    WHEN MATCHED THEN\n",
    "                        UPDATE SET\n",
    "                            target.product_code = source.product_code,\n",
    "                            target.product_name = source.product_name,\n",
    "                            target.product_line = source.product_line,\n",
    "                            target.product_scale = source.product_scale,\n",
    "                            target.product_vendor = source.product_vendor,\n",
    "                            target.product_description = source.product_description,\n",
    "                            target.quantity_in_stock = source.quantity_in_stock,\n",
    "                            target.buy_price = source.buy_price,\n",
    "                            target.msrp = source.msrp\n",
    "                    WHEN NOT MATCHED BY target THEN\n",
    "                        INSERT *\n",
    "                    WHEN NOT MATCHED BY source THEN\n",
    "                        DELETE \"\"\" \n",
    "}\n",
    "\n",
    "def parquet_jdbc_merge(pgsql_dfs, tabelas):\n",
    "    try:\n",
    "        for tabela in tabelas:\n",
    "            # Lendo o arquivo Parquet e pegando a sua tabela postgre\n",
    "            parquet_path = f\"/Users/dev-torugo/{tabela}.parquet\"\n",
    "            delta_path = f\"/Users/dev-torugo/{tabela}_delta\"\n",
    "            df_parquet = spark.read.parquet(parquet_path)\n",
    "\n",
    "            #Criar Delta Lake para o parquet\n",
    "            df_parquet.write.format('delta').mode('overwrite').option(\"overwriteSchema\", \"true\").save(f'{delta_path}')\n",
    "            df_delta = spark.read.format(\"delta\").load(delta_path)\n",
    "\n",
    "\n",
    "            df_delta.createOrReplaceTempView(\"tabela_delta\") # Cria uma view temporária para a tabela Delta\n",
    "            pgsql_df = pgsql_dfs[tabela] # Obtém o DataFrame correspondente à tabela PostgreSQL\n",
    "            pgsql_df.createOrReplaceTempView(\"tabela_postgresql\") # Cria uma view temporária para a tabela PostgreSQL\n",
    "\n",
    "            merge = merge_querys[tabela]\n",
    "\n",
    "            spark.sql(merge)\n",
    "            spark.catalog.dropTempView(\"tabela_postgresql\")\n",
    "            print(f\"{tabela} merged.\")\n",
    "        print(\"Todas as tabelas foram processadas)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "#Uso\n",
    "parquet_jdbc_merge(pgsql_dfs, tabelas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "474d3f17-d573-41b7-9f3d-4217e8b30b5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#FERRAMENTA AUXILIAR PARA AS RESPOSTAS DA QUESTÃO 5\n",
    "\n",
    "# Esta função utiliza o Spark para consultar dados de e-commerce de uma fonte JDBC especificada pela URL e tabela fornecidas. Os resultados são armazenados em um arquivo Delta no caminho especificado, permitindo a substituição do esquema anterior. Em caso de erro, a função exibe uma mensagem de erro detalhada.\n",
    "\n",
    "def query_ecommerce_data (url, table, properties):\n",
    "    try:\n",
    "        df = spark.read.jdbc(url,\n",
    "                            table,\n",
    "                            properties=propriedades)\n",
    "        file_path = 'Users/dev-torugo/'\n",
    "        df.write.format('delta').mode('overwrite').option(\"overwriteSchema\", \"true\").save(f'{file_path}')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Erro: {e}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da2dae83-56bf-4e76-808e-829eb0caddfc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QUESTÃO 5.1 - Qual país possui a maior quantidade de itens cancelados?\n",
    "\n",
    "query_Q5_1 = '''\n",
    "(   SELECT DISTINCT c.country AS pais, SUM(dos.quantity_ordered) AS total_itens_cancelados\n",
    "    FROM public.customers c \n",
    "    LEFT JOIN public.orders os ON c.customer_number = os.customer_number\n",
    "    LEFT JOIN orderdetails dos ON dos.order_number = os.order_number\n",
    "    WHERE os.status = 'Cancelled'\n",
    "    GROUP BY c.country\n",
    "    ORDER BY total_itens_cancelados DESC\n",
    "    LIMIT 1) AS subquery\n",
    "'''\n",
    "\n",
    "df_qtd_cancelados = query_ecommerce_data(jdbc_url, query_Q5_1, propriedades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f9ae98-f183-4724-8061-957b13e76221",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------+\n",
      "| pais|total_itens_cancelados|\n",
      "+-----+----------------------+\n",
      "|Spain|                   605|\n",
      "+-----+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_qtd_cancelados.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8274ed32-9262-4eef-8454-b9eb74f41e82",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QUESTÃO 5.2 - Qual o faturamento da linha de produto mais vendido, considere os itens com status 'Shipped', cujo o pedido foi realizado no ano de 2005?\n",
    "\n",
    "query_Q5_2 = '''\n",
    "    (SELECT pd.product_line,\n",
    "     SUM(p.amount) AS faturamento\n",
    "    FROM products pd\n",
    "    LEFT JOIN orderdetails od ON od.product_code  = pd.product_code\n",
    "    LEFT JOIN orders o ON o.order_number  = od.order_number \n",
    "    LEFT JOIN payments p ON p.customer_number = o.customer_number \n",
    "    WHERE o.status = 'Shipped' AND EXTRACT(year FROM o.order_date) = 2005\n",
    "    GROUP BY pd.product_line\n",
    "    ORDER BY faturamento DESC\n",
    "    LIMIT 1) As subquery\n",
    "'''\n",
    "\n",
    "df_produto_2005 = query_ecommerce_data(jdbc_url, query_Q5_2, propriedades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b454686-3df7-40d4-a90d-1d079cf5dfe2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|product_line|         faturamento|\n",
      "+------------+--------------------+\n",
      "|Classic Cars|47574393.22000000...|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_produto_2005.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644de670-f6b0-439a-be4f-36352b750868",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QUESTÃO 5.3 - Nome, sobrenome e e-mail dos vendedores do Japão, o local-part do e-mail deve estar mascarado.\n",
    "\n",
    "query_Q5_3 = '''\n",
    "(   SELECT\n",
    "        e.first_name AS nome,\n",
    "        e.last_name AS sobrenome,\n",
    "        CONCAT(REPEAT('*', POSITION('@' IN e.email) - 1), SUBSTRING(e.email, POSITION('@' IN e.email))) AS email\n",
    "    FROM employees e \n",
    "    LEFT JOIN offices o \n",
    "    ON o.office_code = e.office_code \n",
    "    WHERE o.country = 'Japan'\n",
    "    ) As subquery\n",
    "    '''\n",
    "\n",
    "df_vendedores_japao = query_ecommerce_data(jdbc_url, query_Q5_3, propriedades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a598649d-ef0f-4259-a7c9-0d1c2d5c8d87",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+\n",
      "|   nome|sobrenome|               email|\n",
      "+-------+---------+--------------------+\n",
      "|   Mami|    Nishi|******@classicmod...|\n",
      "|Yoshimi|     Kato|*****@classicmode...|\n",
      "+-------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_vendedores_japao.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RNP - E-COMMERCE DATA CASE",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
